{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14529b41",
   "metadata": {},
   "source": [
    "# pyAFQ tractography pipeline (adapted for Moramay Ramos-Flores)\n",
    "\n",
    "This notebook explains **step by step** what each import, function, and parameter does.\n",
    "All explanations are included directly above each code cell.\n",
    "You must have:\n",
    "- pyAFQ installed (`pip install pyafq`)\n",
    "- Your diffusion data organized in **BIDS format**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb60ab",
   "metadata": {},
   "source": [
    "## 1. Import libraries\n",
    "\n",
    "Here we import all the modules needed. Each one has a specific role.\n",
    "\n",
    "- `AFQ.api.bundle_dict`: lets you load default bundles or create custom ones.\n",
    "- `AFQ.data.fetch`: contains the datasets (e.g., `stanford_hardi`).\n",
    "- `GroupAFQ`: main class to run pyAFQ on a whole BIDS dataset.\n",
    "- `ImageFile` and `RoiImage`: used to define masks, ROIs, and their logic (include/exclude).\n",
    "- `os` and `os.path`: used to build file paths safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import AFQ.api.bundle_dict as abd\n",
    "import AFQ.data.fetch as afd\n",
    "from AFQ.api.group import GroupAFQ\n",
    "import AFQ.utils.streamlines as aus\n",
    "from AFQ.definitions.image import ImageFile, RoiImage\n",
    "import AFQ.definitions.image as afm\n",
    "import os\n",
    "import os.path as op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f851f3",
   "metadata": {},
   "source": [
    "## 2. Select the bundles to analyze\n",
    "\n",
    "Here we select **a subset** of the 18 default bundles provided by pyAFQ.\n",
    "\n",
    "The list `other_bundles` contains the names exactly as pyAFQ defines them. These names must match the keys in the `default18_bd()` dictionary.\n",
    "\n",
    "`abd.default18_bd()` → returns *all* 18 bundles defined by pyAFQ.\n",
    "\n",
    "`abd.default18_bd()[other_bundles]` → extracts only the bundles we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_bundles = [\n",
    "    \"Left Arcuate\", \"Right Arcuate\",\n",
    "    \"Left Inferior Fronto-occipital\", \"Right Inferior Fronto-occipital\",\n",
    "    \"Left Inferior Longitudinal\", \"Right Inferior Longitudinal\",\n",
    "    \"Left Superior Longitudinal\", \"Right Superior Longitudinal\",\n",
    "    \"Left Uncinate\", \"Right Uncinate\"\n",
    "]\n",
    "\n",
    "bundles = abd.default18_bd()[other_bundles]\n",
    "bundles.bundle_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fd3e2",
   "metadata": {},
   "source": [
    "## 3. Define brain mask logic\n",
    "\n",
    "pyAFQ needs a **brain mask** for tractography.\n",
    "\n",
    "- `suffix='mask'` tells pyAFQ to search for files ending in `*mask.nii.gz`\n",
    "- `filters={'scope': 'freesurfer'}` restricts the search to masks generated by FreeSurfer.\n",
    "- `exclusive_labels=[0]` tells pyAFQ to treat label 0 (background) as excluded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ce2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask_definition = afm.LabelledImageFile(\n",
    "    suffix='mask',\n",
    "    filters={'scope': 'freesurfer'},\n",
    "    exclusive_labels=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b0d9b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Initialize GroupAFQ\n",
    "\n",
    "This is the **core object** that runs the entire bundle extraction pipeline.\n",
    "\n",
    "### Explanation of parameters:\n",
    "- `op.join(afd.afq_home,'stanford_hardi')` → loads the Stanford HARDI the dataset.\n",
    "- `bundle_info=bundles` → the subset of bundles we selected.\n",
    "- `preproc_pipeline='vistasoft'` → tells pyAFQ how the dataset the DWI images was preprocessed.\n",
    "- `scalars=[\"dki_fa\"]` → pyAFQ extracts FA along the tract.\n",
    "- `tracking_params` → controls tractography:\n",
    "  - `n_seeds=1000000`: how many seeds per subject.\n",
    "  - `random_seeds=True`: seeds are randomly distributed inside the seed mask.\n",
    "  - `seed_mask=RoiImage(...)`: defines where streamlines can begin.\n",
    "\n",
    "pyAFQ automatically identifies all DWI and anatomical files following the BIDS specification. No manual file selection is required.\n",
    "\n",
    "Because the analysis uses dki_fa, pyAFQ automatically fits a Diffusion Kurtosis Imaging (DKI) model using weighted least-squares (default DIPY implementation). Additional DKI-derived metrics (mean, axial, and radial kurtosis) are computed implicitly.\n",
    "Registration follows pyAFQ’s default two-step pipeline: affine alignment of the subject’s DKI-FA map to the template, followed by SyN non-linear registration.\n",
    "\n",
    "Fiber orientation reconstruction is performed using pyAFQ’s default single-tissue Constrained Spherical Deconvolution model (CSD; response function estimated using the Tournier method, SH order l=8).\n",
    "\n",
    "Streamlines were generated using probabilistic CSD tracking with pyAFQ’s default settings (0.5 mm step size, 30° curvature threshold, 30–250 mm allowed lengths).\n",
    "1,000,000 random seeds were used, and waypoint/endpoints masks were enforced.\n",
    "\n",
    "Bundle segmentation follows the default pyAFQ logic, combining waypoint-based inclusion/exclusion, probabilistic atlas matching, and automatic removal of anatomically inconsistent streamlines.\n",
    "\n",
    "Tract cleaning applies the standard pyAFQ procedure: length-based trimming (5%), Mahalanobis distance thresholding (5), and resampling of streamlines to 100 equidistant nodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cb696",
   "metadata": {},
   "outputs": [],
   "source": [
    "myafq = GroupAFQ(\n",
    "    op.join(afd.afq_home, 'stanford_hardi'),\n",
    "    bundle_info=bundles,\n",
    "    brain_mask_definition=brain_mask_definition,\n",
    "    preproc_pipeline='vistasoft',\n",
    "    scalars=[\"dki_fa\"],\n",
    "    tracking_params={\n",
    "        \"n_seeds\": 1000000,\n",
    "        \"random_seeds\": True,\n",
    "        \"seed_mask\": RoiImage(use_waypoints=True, use_endpoints=True)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56a070da",
   "metadata": {},
   "source": [
    "## 5. Export results\n",
    "\n",
    "`export_all()` generates outputs including:\n",
    "- Tract profiles (.csv with tractID, nodeID, dki_fa, subjetID,sessionID)\n",
    "- Streamlines\n",
    "- Bundle segmentations\n",
    "\n",
    "Here we disable visualizations to speed up processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myafq.export_all(\n",
    "    viz=False,\n",
    "    afqbrowser=False,\n",
    "    xforms=False,\n",
    "    indiv=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
